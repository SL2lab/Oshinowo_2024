{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4028f3d",
   "metadata": {},
   "source": [
    "### TikTok analysis methods ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f20db1",
   "metadata": {},
   "source": [
    "Prepared for manuscript \"*Engineering the communication of science through social media*\" by Oshinowo et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9573ce8",
   "metadata": {},
   "source": [
    "Analysis is divided into the following sections:\n",
    " 1. Correlation analysis of interest signals\n",
    " 2. K-means clustering analysis\n",
    " 3. Linear regression analysis\n",
    " 4. Sentiment analysis with word cloud analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754111ec",
   "metadata": {},
   "source": [
    "For an accessible introduction to machine learning, please feel free to read the review \"A guide to machine learning for biologists\" by Greener et al., 2021, published in journal [Nature Reviews Molecular Cell Biology](https://www.nature.com/articles/s41580-021-00407-0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d12527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "# File management\n",
    "import os  # For directory management\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Number and file management\n",
    "import numpy as np  # For array management\n",
    "import pandas as pd  # For database management\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt  # For plotting result data\n",
    "import seaborn as sns\n",
    "\n",
    "# Mathematical methods\n",
    "from scipy.ndimage import label\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import measure, util\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# NLP methods\n",
    "import sys\n",
    "!{sys.executable} -m textblob.download_corpora\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461364c2",
   "metadata": {},
   "source": [
    "#### 1. Correlation analysis of interest signals ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289a99a",
   "metadata": {},
   "source": [
    "Correlation matrices are a statistical technique used to evaluate the relationship between two variables in a data set. In the produced table, every cell contains a Pearson correlation coefficient. +1 is considered a strong positive association between variables, 0 a neutral relationship, and -1 a strong inverse relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0801d95",
   "metadata": {},
   "source": [
    "Python programming methods are based upon library [Pandas](https://pandas.pydata.org/) version 2.2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filedialog.askopenfile()  # Select excel sheet of data, read\n",
    "df = pd.read_excel(file, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9047c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Correlation_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4be875",
   "metadata": {},
   "source": [
    "#### 2. K-means clustering analysis ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d203c1",
   "metadata": {},
   "source": [
    "Clustering analyses are a label-free machine learning method designed to find natural groupings with data sets. Here, k-means algorithms, understood to be a robust general approach to clustering, group data points into a specified *k* number of clusters in which each observation belongs to the cluster with the nearest mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca8d8b",
   "metadata": {},
   "source": [
    "Python programming methods are based upon freely available, open source library [scikit-learn](https://scikit-learn.org/stable/) version 1.4. Algorithms are described in manuscript \"*Algorithm AS 136: A K-means clustering algorithm*\" by J. A. Hartigan and M. A. Wong, 1979, published in journal [Journal of the Royal Statistical Society](https://www.jstor.org/stable/2346830)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scree plot\n",
    "sse = {}\n",
    "df_scree = df_X.copy()  # Leave original X set unchanged\n",
    "for k in range(1, 12):  # Range of 1 to 12 clusters, could easily edit\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_scree)\n",
    "    df_scree[\"Clusters\"] = kmeans.labels_\n",
    "    #print(data[\"clusters\"])\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Selected_features_scree.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After consulting the scree plot, input a number of clusters (k) to parition all data points into\n",
    "# i.e. k = 2\n",
    "k = 4 # Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=100)\n",
    "kmeans_labels = kmeans.fit_predict(df_X)  # Note each label will be an integer, starting at 0 (0, 1, 2.. etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ce063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe that includes sample name, all feature metric values, and labels\n",
    "df_with_labels = df.copy()\n",
    "df_with_labels['Label'] = kmeans_labels\n",
    "print(df_with_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ba84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette score to assess goodness of clustering\n",
    "# -1 indicates poor clustering, 1 indicates perfect clustering\n",
    "silhouette_coefficient = metrics.silhouette_score(df_X, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26edb5e6",
   "metadata": {},
   "source": [
    "#### 3. Linear regression analysis ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4fae2",
   "metadata": {},
   "source": [
    "Regression analyses are used to mathematically characterize the value of a dependent variable (y-axis) based upon the value of an independent variable (x-axis). Here, we performed paired value analysis with views as the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d48d2",
   "metadata": {},
   "source": [
    "Python programming methods are based upon freely available, open source library [scikit-learn](https://scikit-learn.org/stable/) version 1.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df570195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model and fit it\n",
    "model = LinearRegression()\n",
    "# For multivariate analysis: several x variables, one y variable\n",
    "y_block = 'Views'  # Column name for y block, all remaining variables are x block variables\n",
    "Y = df[y_block]\n",
    "X = df.drop(columns=[y_block])\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9612787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weights assigned to each feature\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(X.columns, model.coef_)\n",
    "plt.ylabel('weight')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Regression_weights.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d304276",
   "metadata": {},
   "source": [
    "#### 4. Sentiment analysis ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd7096",
   "metadata": {},
   "source": [
    "Sentiment analysis, a subset of the field of natural language processing, classifies individual words or groups of words (here, a comment) as having a positive (value greater than zero with a maximum value of 1), neutral (value of zero), or negative (value less than zero with a maximum value of -1) polarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2689af",
   "metadata": {},
   "source": [
    "To organize .csv files of individual comments, we used [TTCommentExplorer](https://chromewebstore.google.com/detail/ttcommentexporter-export/epjbmmchkjlgmogfoamcleeikmfaffjm?pli=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572c91c",
   "metadata": {},
   "source": [
    "Python methods are based upon freely available, open source library [Natural Learning Toolkit](https://www.nltk.org/) version 1.8. Algorithms are described in manuscript #*Sentiment analysis: capturing favorability using natural language processing*\" by T. Nasukawa and J. Li in the journal [Association for Computing Machinery](https://dl.acm.org/doi/abs/10.1145/945645.945658). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7819bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose directory of .csv files\n",
    "directory = filedialog.askopendirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd84a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .csv list\n",
    "csv_list = sorted(glob.glob(directory + \"/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of comments\n",
    "\n",
    "df = pd.DataFrame(columns=['ID', 'Comments'])\n",
    "for csv in csv_list:\n",
    "    \n",
    "    comment_df = pd.read_csv(csv)\n",
    "    comment_list = comment_df['Comment'].tolist()\n",
    "    comment_dict = {'ID': Path(csv).stem,\n",
    "                    'Comments': comment_list}\n",
    "    \n",
    "    df = df.append(comment_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e988276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one large word cloud\n",
    "comment_list_all = df_words['Comments'].tolist()\n",
    "flat_list = [item for sublist in comment_list_all for item in sublist]\n",
    "one_string = \" \".join(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a843d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61307477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra characters\n",
    "def remove_all(one_string_updated_nopunc):\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('...', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u2026', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u0022', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u0027', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u201C', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u201D', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\\u2019', '')\n",
    "    one_string_updated_nopunc = one_string_updated_nopunc.replace('\"', '')\n",
    "    \n",
    "    return one_string_updated_nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df_sia = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze individual words or comments\n",
    "df_all_polarity = pd.DataFrame()\n",
    "    \n",
    "word_list = []\n",
    "polarity_list = []\n",
    "cat_list = []\n",
    "sub_list = []\n",
    "    \n",
    "# Clean words\n",
    "comment_list_all = df_words['Comments'].tolist()\n",
    "flat_list = [item for sublist in comment_list_all for item in sublist]\n",
    "one_string = \" \".join(flat_list)\n",
    "# Remove emojis\n",
    "one_string_updated = remove_emojis(one_string)\n",
    "    \n",
    "# Remove punctuation\n",
    "one_string_updated_nopunc = one_string_updated.translate(str.maketrans('', '', string.punctuation))\n",
    "one_string_updated_nopunc = remove_all(one_string_updated_nopunc)\n",
    "list_words = one_string_updated_nopunc.split()\n",
    "    \n",
    "for word in list_words:\n",
    "    cat_list.append(cat)\n",
    "    word_list.append(word)\n",
    "    polarity_list.append(TextBlob(word).sentiment.polarity)\n",
    "\n",
    "# for comment in flat_list:\n",
    "#     print(comment)\n",
    "#     cat_list.append(cat)\n",
    "#     word_list.append(comment)\n",
    "#     polarity_list.append(TextBlob(comment).sentiment.polarity)\n",
    "        \n",
    "df_all_polarity['Category'] = cat_list\n",
    "df_all_polarity['Word'] = word_list\n",
    "\n",
    "# df_all_polarity['Comment'] = word_list\n",
    "\n",
    "df_all_polarity['Polarity'] = polarity_list\n",
    "    \n",
    "with pd.ExcelWriter('Word_polarity.xlsx') as writer:\n",
    "    df_all_polarity.to_excel(writer, sheet_name='Words')\n",
    "    \n",
    "# with pd.ExcelWriter('Comment_polarity.xlsx') as writer:\n",
    "#     df_all_polarity.to_excel(writer, sheet_name='Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf9940",
   "metadata": {},
   "source": [
    "Word clouds are groupings of words with size of text indicating relative frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a28b86",
   "metadata": {},
   "source": [
    "Python methods are based upon freely available, open source library [WordCloud](https://github.com/amueller/word_cloud) version 1.8.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de736c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(background_color='white', colormap='binary', width=800, height=500).generate(one_string_updated_nopunc)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('Word_cloud.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
